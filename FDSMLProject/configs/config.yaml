defaults:
  - model: glyphnet
  - optimizer: adam
  - override hydra/launcher: joblib
  - _self_

data:
  train_path: "balanced_data/train/"
  val_fraction: 0.3
  test_path: "balanced_data/test/"

model:
  batch_size: 8
  epochs: 20
  log_progress_steps: 1000
  learning_rate: 0.001
  seed: 261

hydra:
  job:
    config:
      override_dirname:
        exclude_keys:
          - model.log_progress_steps
  run:
    dir: ./results/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: results/${data.path}/
    subdir: ${hydra.job.override_dirname}
  help:
    template:
      "This is the script for training GlyphNet reimplemented in PyTorch"